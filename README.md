# SmartFaqRag ğŸš€

A simple and powerful **RAG (Retrieval-Augmented Generation)** pipeline built with **Spring AI** and **Spring Boot** for intelligent FAQ management and question answering.

---

## ğŸ¯ What is this?

**SmartFaqRag** helps you build an intelligent FAQ system that can:

- ğŸ§  Store and search through your documents  
- ğŸ’¬ Answer questions based on your content  
- âš™ï¸ Use any AI model you want (local or paid)

---

## âœ¨ Features

- ğŸ” **Smart Document Search** â€” Find relevant information quickly  
- ğŸ¤– **Flexible Model Support** â€” Use any local or paid AI model  
- ğŸŒ **OpenRouter Integration** â€” Seamless access to 100+ models through one API  
- ğŸ“š **Easy Document Management** â€” Simple APIs to add and query documents  
- ğŸš€ **Spring Boot** â€” Fast, reliable, and easy to deploy  

---

## ğŸ› ï¸ Quick Start

### Prerequisites

- **Java 17+**
- **Maven** or **Gradle**

---

### âš™ï¸ Installation

1. **Clone the repo**
   ```bash
   git clone https://github.com/sagnikghosal007/SmartFaqRag.git
   cd SmartFaqRag
2. **Configure Your Model**

Choose **one** of the following configuration options and update your `application.properties` file accordingly.

---

### ğŸ…°ï¸ Option 1: Using OpenRouter (Recommended)

```properties
# application.properties
spring.ai.openai.base-url=https://openrouter.ai/api/v1
spring.ai.openai.api-key=${OPENROUTER_API_KEY}
spring.ai.openai.chat.options.model=meta-llama/llama-3.1-8b-instruct:free
```


### ğŸ…±ï¸ Option 2: Using Local Models (LM Studio)

```properties
# application.properties
spring.ai.openai.base-url=http://localhost:1234/v1
spring.ai.openai.api-key=lm-studio
```
### ğŸ† Option 3: Using Other Paid APIs

```properties
# OpenAI
spring.ai.openai.api-key=${OPENAI_API_KEY}

# OR Anthropic
spring.ai.anthropic.api-key=${ANTHROPIC_API_KEY}
```
## â–¶ï¸ Run the Application

```bash
./mvnw spring-boot:run
```

## ğŸ¤– Model Options

### ğŸª„ Option 1: OpenRouter (Easiest Way)

Use [**OpenRouter**](https://openrouter.ai/) to access multiple AI models through a single API key.

âœ… **Free models:** Llama, Mistral, etc.  
ğŸ’ **Paid models:** GPT-4, Claude, Gemini, and 100+ others  
ğŸ”‘ **Single API key** for everything  
ğŸ’° **Pay-as-you-go** pricing  

Get your API key here: [https://openrouter.ai/](https://openrouter.ai/)

---

### ğŸ–¥ï¸ Option 2: Local Models (via LM Studio)

Run models locally on your own machine.

1. Download [**LM Studio**](https://lmstudio.ai/)  
2. Load any compatible model (Llama, Mistral, etc.)  
3. Start the local inference server  
4. Update your app configuration: spring.ai.openai.base-url=http://localhost:1234/v1


---

### ğŸ”— Option 3: Direct API Access

Use APIs directly from major AI providers:

- **OpenAI:** GPT-3.5, GPT-4  
- **Anthropic:** Claude models  
- **Others:** Any OpenAI-compatible API  

---

## ğŸ”® Coming Soon

- ğŸ“ **Document Upload API** â€” Add your own documents dynamically  
- ğŸ§® **PostgreSQL + pgvector** â€” Production-grade vector storage for scalability  
- ğŸ’¬ **Conversation History**  
- ğŸ§¾ **Multiple Document Formats**  
- âš¡ **Batch Processing**  

---

## ğŸ§  Architecture Overview

flowchart TD
    A[ğŸ§‘ User Query (API)] --> B[ğŸ” Retriever Layer<br/>(Embeddings + Vector Search)]
    B --> C[ğŸ§  LLM Reasoning Layer<br/>(Spring AI + Chosen Model)]
    C --> D[ğŸ’¬ Final Answer Output]



---

## ğŸ¤ Contributing

Pull requests are welcome! Feel free to:

- ğŸ Report bugs  
- ğŸ’¡ Suggest features  
- ğŸ§° Improve documentation  

---

## ğŸ§‘â€ğŸ’» Author

**Sagnik Ghosal**






